\newpage


\begin{thebibliography}{10}
\bibitem{cifar10}
	\textit{Alex Krizhevsky and Vinod Nair and Geoffrey Hinton} CIFAR-10 (Canadian Institute for Advanced Research) // \url{http://www.cs.toronto.edu/~kriz/cifar.html}
\bibitem{imagenet}
	\textit{Deng, J., Dong, W., Socher, R., Li, L.-J., Li, K., Fei-Fei, L. } Imagenet: A large-scale hierarchical image database //  IEEE conference on computer vision and pattern recognition, 2009. P. 248--255. 
	
\bibitem{Zehao2017}
	\textit{{Huang}, Zehao and {Wang}, Naiyan} Like What You Like: Knowledge Distill via Neuron Selectivity Transfer // arXiv e-prints, 2017.
\bibitem{Zheng2020}
	\textit{Kui Ren and Tianhang Zheng and Zhan Qin and Xue Liu} Adversarial Attacks and Defenses in Deep Learning // Engineering, 2020. P. 346--360.
\bibitem{Krizhevsky2012}
	\textit{Alex Krizhevsky, Ilya Sutskever, Geoffrey Hinton} ImageNet Classification with Depp Convolutional Neural Networks // NIPS, 2012.
\bibitem{Simonyan2014}
	\textit{Karen Simonyan and Andrew Zisserman} Very Deep Convolutional Networks for Large-Scale Image Recognition // NIPS, 2014.
\bibitem{Vaswani2017}
	\textit{Vaswani A., Shazeer N., Parmar N., Uszkoreit J., Jones L., Gomez A., Kaiser L., Polosukhin I.} Attention Is All You Need // In Advances in Neural Information Processing Systems. 2017. V. 5. P. 6000--6010.
\bibitem{Devlin2018}
       \textit{Devlin J., Chang M., Lee K., Toutanova K.} BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding // arXiv preprinted, 2018.
\bibitem{Brown2020}
        \textit{Tom B. Brown et al} GPT3: Language Models are Few-Shot Learners // arXiv preprinted, 2020.
\bibitem{Linting2021}
        \textit{Linting Xue and Noah Constant and Adam Roberts and Mihir Kale and Rami Al-Rfou and Aditya Siddhant and Aditya Barua and Colin Raffel.} mT5: A massively multilingual pre-trained text-to-text transformer // arXiv preprinted, 2021.
\bibitem{Ziqing2020}
        \textit{Yang, Ziqing and Cui, Yiming and Chen, Zhipeng and Che, Wanxiang and Liu, Ting and Wang, Shijin and Hu, Guoping} {T}ext{B}rewer: {A}n {O}pen-{S}ource {K}nowledge {D}istillation {T}oolkit for {N}atural {L}anguage {P}rocessing // Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics: System Demonstrations.  2020. P. 9--16.
\bibitem{Kaiming2015}
	\textit{He K., Zhang X., Ren S., Sun J.} Deep Residual Learning for Image Recognition // Proc. of the IEEE Conference on Computer Vision and Pattern Recognition. Las Vegas, 2016. P. 770--778.
\bibitem{bachteev2018}
	\textit{Бахтеев О.\,Ю., Стрижов В.\,В.} Выбор моделей глубокого обучения субоптимальной сложности // АиТ. 2018. № 8. С. 129--147.
\bibitem{Hinton2015}
        \textit{Hinton G., Vinyals O., Dean J.} Distilling the Knowledge in a Neural Network // NIPS Deep Learning and Representation Learning Workshop. 2015.
\bibitem{mnist}
	\textit{LeCun Y.,  Cortes C., Burges C.} The MNIST dataset of handwritten digits, 1998. \text{http://yann.lecun.com/exdb/mnist/index.html}.
\bibitem{Vapnik2015}
	\textit{Vapnik V., Izmailov R.} Learning Using Privileged Information: Similarity Control and Knowledge Transfer // Journal of Machine Learning Research. 2015. No 16. P. 2023--2049.
\bibitem{Lopez2016}
	\textit{Lopez-Paz D., Bottou L., Scholkopf B., Vapnik V.} Unifying Distillation and Privileged Information // In International Conference on Learning Representations. Puerto Rico, 2016.
\bibitem{Ivakhnenko1994}
	\textit{Madala H., Ivakhnenko A.} Inductive Learning Algorithms for Complex Systems Modeling. Boca Raton: CRC Press Inc., 1994.
\bibitem{fashionmnist}
	\textit{Xiao H., Rasul K.,Vollgraf R.} Fashion-MNIST: a Novel Image Dataset for Benchmarking Machine Learning Algorithms // arXiv preprint arXiv:1708.07747. 2017.
\bibitem{twiter2013}
	\textit{Wilson T., Kozareva Z., Nakov P., Rosenthal S., Stoyanov V., Ritter A.} {S}em{E}val-2013 Task 2: Sentiment Analysis in Twitter // Proceedings of the Seventh International Workshop on Semantic Evaluation ({S}em{E}val 2013). Atlanta, 2013. P. 312--320.
\bibitem{LeCun1989}
	\textit{LeCun Y., Boser B., Denker J., Henderson D., Howard R., Hubbard W., Jackel L.} Backpropagation Applied to Handwritten Zip Code Recognition // Neural Computation. 1989. V. 1. No 4. P. 541--551.
\bibitem{Schmidhuber1997}
	\textit{Hochreiter S., Schmidhuber J.} Long short-term memory // Neural Computation. 1997. V. 9. No 8.  P. 1735--1780.
\bibitem{kingma2014}
	\textit{Kingma D, Ba J.} Adam: A Method for Stochastic Optimization // arXiv preprint arXiv:1412.6980. 2014.
\bibitem{graves2011}
	\textit{Graves A.} Practical Variational Inference for Neural Networks // Advances in Neural Information Processing Systems, 2011. Vol. 24. P. 2348--2356.
\bibitem{Vapnik2015}
	\textit{Vapnik V., Izmailov R.} Learning Using Privileged Information: Similarity Control and Knowledge Transfer // Journal of Machine Learning Research. 2015. No 16. P. 2023--2049.
\bibitem{Lopez2016}
	\textit{Lopez-Paz D., Bottou L., Scholkopf B., Vapnik V.} Unifying Distillation and Privileged Information // In International Conference on Learning Representations. Puerto Rico, 2016.
	
\bibitem{sutskever2014}
	\textit{Sutskever I., Vinyals O., Le Q.} Sequence to Sequence Learning with Neural Networks~// Advances in Neural Information Processing Systems, 2014. Vol.~2. P.~3104--3112.
	
\bibitem{Chunyan2016}
	\textit{Li C., Chen C., Carlson D., Carin L.} Preconditioned Stochastic Gradient Langevin Dynamics for Deep Neural Networks~// Thirtieth AAAI Conference on Artificial Intelligence.~---~Phoenix, USA, 2016. P.~1788--1794.
	
\bibitem{Tibshirani1996}
	\textit{Tibshirani R.} Regression shrinkage and selection via the Lasso~// Journal of the Royal Statistical Society, 1996. Vol.~58. P.~267--288.
	
\bibitem{Hastie2005}
	\textit{Zou H., Hastie T.} Regularization and variable selection via the Elastic Net~// Journal of the Royal Statistical Society, 2005. Vol.~67. P.~301--320.
	
\bibitem{srivastava2014}
	\textit{Srivastava N., Hinton G., Krizhevsky A., Sutskever I., Salakhutdinov R.} Dropout: A Simple Way to Prevent Neural Networks from Overfitting~// Journal of Machine Learning Research, 2014. Vol.~15. P.~1929--1958.
	
\bibitem{molchanov2017}
	\textit{Molchanov D., Ashukha A., Vetrov D.} Variational Dropout Sparsifies Deep Neural Networks~// 34th International Conference on Machine Learning.~---~Sydney, Australia, 2017. Vol.~70. P.~2498--2507.
	
\bibitem{cun1990}
	\textit{LeCun Y., Denker J., Solla S.} Optimal Brain Damage~// Advances in Neural Information Processing Systems, 1989. Vol.~2. P.~598--605.
	
\bibitem{grabovoy2019}
	\textit{Грабовой А. В., Бахтеев О. Ю., Стрижов В. В.} Определение релевантности параметров нейросети~// Информатика и ее применения, 2019. Т.~13. Вып.~2. С.~62--70.
\bibitem{grabovoy2020}
	\textit{Грабовой А. В., Бахтеев О. Ю., Стрижов В. В.} Введение отношения порядка на множестве параметров аппроксимирующих моделей~// Информатика и ее применения, 2019. Т.~14. Вып.~2. С.~58--65.

\bibitem{Mandt2017}
	\textit{Mandt S., Hoffman M., Blei D.} Stochastic Gradient Descent as Approximate Bayesian Inference~// Journal Of Machine Learning Research, 2017. Vol.~18. P.~1--35.
	
\bibitem{Kingma2014}
	\textit{Kingma D., Ba L.} Adam: A Method for Stochastic Optimization~// 3rd International Conference on Learning Representations.~---~San Diego, USA, 2015.

\bibitem{Boston}
	\textit{Harrison D.,  Rubinfeld D.} Hedonic prices and the demand for clean air~// Journal of Environmental Economics and Management, 1991. Vol.~5. P.~81--102.

\bibitem{mnist}
	\textit{LeCun Y.,  Cortes C., Burges C.} The MNIST dataset of handwritten digits, 1998. \url{http://yann.lecun.com/exdb/mnist/index.html}

\bibitem{maclarin2015}
	\textit{Maclaurin D.,  Duvenaud D., Adams R.} Gradient-based Hyperparameter Optimization Through Reversible Learning~// Proceedings of the 32th International Conference on Machine Learning, 2015. Vol.~37. P.~2113--2122.
\bibitem{luketina2015}
	\textit{Luketina J.,  Berglund M., Raiko T., Greff K.} Scalable Gradient-based Tuning of Continuous Regularization Hyperparameters~// Proceedings of the 33th International Conference on Machine Learning, 2016. Vol.~48. P.~2952--2960.
\bibitem{bishop2006}
	\textit{Bishop C.} Pattern Recognition and Machine Learning, 2006. Pp.~396.
\bibitem{neychev2016}
	\textit{Neychev R.,  Katrutsa A., Strijov V.} Robust selection of multicollinear features in forecasting~// Factory Laboratory, 2016. Vol.~82. P.~68--74.
\bibitem{cun1990}
	\textit{LeCun Y.,  Denker J., Solla S.} Optimal Brain Damage~// Advances in Neural Information Processing Systems, 1989. P.~598--605.
\bibitem{molchanov2017}
	\textit{Molchanov D.,  Ashukha A., Vetrov D.} Variational Dropout Sparsifies Deep Neural Networks~// Proceedings of the 34th International Conference on Machine Learning, 2017. Vol.~70. P.~2498--2507.
\bibitem{neal1995}
	\textit{Neal A.,  Radford M.} Bayesian Learning for Neural Networks, 1995.
\bibitem{sutskever2014}
	\textit{Sutskever I.,  Vinyals O., Le Q.} Sequence to Sequence Learning with Neural Networks, 2014. Vol.~2. P.~3104--3112.
\bibitem{graves2011}
	\textit{Graves A.} Practical Variational Inference for Neural Networks, 2011. P.~2348--2356.
\bibitem{louizos2017}
	\textit{Louizos C., Ullrich K., Welling M.} Bayesian Compression for Deep Learning, 2017. P.~3288--3298.

\end{thebibliography}